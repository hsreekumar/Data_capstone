{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2746f793-98ed-47fd-91f9-380f51ac2e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, ContinuousParameter\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import TuningStep, TrainingStep\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep, CreateModelStep, TransformStep\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.parameters import ParameterString, ParameterInteger\n",
    "\n",
    "\n",
    "\n",
    "role = 'arn:aws:iam::339712893183:role/SagemakerNotebookRole'\n",
    "sagemaker_session = sagemaker.Session()\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "# Define the S3 bucket and prefix\n",
    "bucket = 'stock-news-sentiment'\n",
    "\n",
    "prefix = 'models'\n",
    "# Define parameters\n",
    "processing_instance_type = ParameterString(name=\"ProcessingInstanceType\", default_value=\"ml.m5.4xlarge\")\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.p3.2xlarge\")\n",
    "training_instance_count = ParameterInteger(name=\"TrainingInstanceCount\", default_value=1)\n",
    "input_data_uri = ParameterString(name=\"InputDataURI\", default_value=f\"s3://{bucket}/Combined_News_DJIA.csv\")\n",
    "\n",
    "# Preprocessing step\n",
    "script_processor = ScriptProcessor(\n",
    "    role=role,\n",
    "    image_uri='683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3',\n",
    "    command=['python3'],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count\n",
    ")\n",
    "\n",
    "preprocessing_step = ProcessingStep(\n",
    "    name=\"PreprocessData\",\n",
    "    processor=script_processor,\n",
    "    inputs=[\n",
    "        sagemaker.processing.ProcessingInput(\n",
    "            source=input_data_uri,\n",
    "            destination='/opt/ml/processing/input'\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source='/opt/ml/processing/train', destination=f's3://{bucket}/output/train'),\n",
    "        ProcessingOutput(output_name=\"test\", source='/opt/ml/processing/test', destination=f's3://{bucket}/output/test'),\n",
    "        ProcessingOutput(output_name=\"validation\", source='/opt/ml/processing/validation', destination=f's3://{bucket}/output/validation')\n",
    "    ],\n",
    "    code='scripts/preprocessing.py'\n",
    ")\n",
    "\n",
    "model_path = f\"s3://{bucket}/models\"\n",
    "\n",
    "\n",
    "pytorch_estimator = PyTorch(\n",
    "    entry_point='train.py',\n",
    "    source_dir='scripts',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    framework_version='1.8.1',\n",
    "    py_version='py3',\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={\n",
    "        'bucket_name': bucket,\n",
    "    },\n",
    "    output_path=model_path\n",
    ")\n",
    "\n",
    "# Define hyperparameter ranges for tuning\n",
    "hyperparameter_ranges = {\n",
    "    'lr': ContinuousParameter(1e-6, 1e-4),  # Learning rate range\n",
    "    'batch_size': IntegerParameter(16, 64)  # Batch size range\n",
    "}\n",
    "\n",
    "# Create a HyperparameterTuner object\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=pytorch_estimator,\n",
    "    objective_metric_name='accuracy',\n",
    "    objective_type='Maximize',  # Choose 'Minimize' if you're optimizing a loss metric\n",
    "    metric_definitions=[\n",
    "        {'Name': 'accuracy', 'Regex': 'Val accuracy ([0-9\\\\.]+)'}\n",
    "    ],\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    max_jobs=1,  # Total number of training jobs\n",
    "    max_parallel_jobs=1  # Number of jobs to run in parallel\n",
    ")\n",
    "\n",
    "\n",
    "# Define the TuningStep\n",
    "tuning_step = TuningStep(\n",
    "    name='TuneHyperparameters',\n",
    "    tuner=tuner,\n",
    "    inputs={\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"train\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "            \"test\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"validation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            )\n",
    "    },\n",
    "    display_name=\"HyperparameterTuning\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get the top model's S3 URI using tuning_step\n",
    "top_model_s3_uri = tuning_step.get_top_model_s3_uri(top_k=0, s3_bucket=bucket, prefix = prefix)\n",
    "\n",
    "# Define the EvaluationStep\n",
    "evaluation_script_processor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(framework='sklearn', region=sagemaker_session.boto_region_name, version='0.23-1'),\n",
    "    command=['python3'],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"NewsSentimentEvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")\n",
    "\n",
    "evaluation_step = ProcessingStep(\n",
    "    name='Evaluation',\n",
    "    processor=evaluation_script_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=top_model_s3_uri, destination='/opt/ml/processing/model'),\n",
    "        ProcessingInput(source=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri, destination='/opt/ml/processing/test')\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source='/opt/ml/processing/evaluation', destination=f's3://{bucket}/evaluation')\n",
    "    ],\n",
    "    code='scripts/evaluate.py',\n",
    "    property_files=[evaluation_report]\n",
    ")\n",
    "\n",
    "# Define the Model object using the best model from TuningStep\n",
    "model = Model(\n",
    "    image_uri=pytorch_estimator.training_image_uri(),\n",
    "    model_data=top_model_s3_uri,  # Use the top model's S3 URI directly\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "# Define the CreateModelStep using the top model's S3 URI\n",
    "create_model_step = CreateModelStep(\n",
    "    name='CreateModel',\n",
    "    model=model,\n",
    "    inputs=sagemaker.inputs.CreateModelInput(instance_type=processing_instance_type)\n",
    ")\n",
    "\n",
    "# Define ModelMetrics for registration\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"s3://{bucket}/evaluation/evaluation.json\",\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Define RegisterModelStep using estimator and model_data\n",
    "register_model_step = RegisterModel(\n",
    "    name=\"RegisterModel\",\n",
    "    estimator=pytorch_estimator,\n",
    "    model_data=top_model_s3_uri,  # Assuming top_model_s3_uri is defined earlier\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[processing_instance_type],\n",
    "    transform_instances=[processing_instance_type],\n",
    "    model_metrics=model_metrics\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Define the ConditionStep\n",
    "condition_step = ConditionStep(\n",
    "    name=\"CheckAUC\",\n",
    "    conditions=[\n",
    "        ConditionGreaterThanOrEqualTo(\n",
    "            left=JsonGet(\n",
    "                step_name=evaluation_step.name,\n",
    "                property_file=evaluation_report,\n",
    "                json_path=\"classification_metrics.auc_score.value\"\n",
    "            ),\n",
    "            right=0.50\n",
    "        )\n",
    "    ],\n",
    "    if_steps=[create_model_step, register_model_step],\n",
    "    else_steps=[]\n",
    ")\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(\n",
    "    name='StockNewsSentimentPipeline2',\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "        training_instance_count,\n",
    "        input_data_uri\n",
    "    ],\n",
    "    steps=[evaluation_step, condition_step],\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "pipeline.create(role_arn=role)\n",
    "# Start the pipeline\n",
    "pipeline.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
